# Application Configuration
app {
  name = "stock-data-processor"
  version = "1.0.0"
}

# Spark Configuration
spark {
  app.name = "StockDataProcessor"
  master = "local[*]"

  sql {
    adaptive.enabled = true
    adaptive.coalescePartitions.enabled = true
    adaptive.skewJoin.enabled = true
  }

  serializer = "org.apache.spark.serializer.KryoSerializer"

  # Memory settings
  executor.memory = "2g"
  driver.memory = "1g"
  executor.cores = 2
}

# Data Processing Configuration
processing {
  default.period.minutes = 10
  watermark.delay = "2 minutes"

  input {
    path = "input/stock_data"
    format = "csv"
  }

  output {
    path = "output/processed_stock_data"
    format = "parquet"
    mode = "overwrite"
  }
}

# Streaming Configuration
streaming {
  trigger.interval = "1 minute"
  checkpoint.location = "checkpoint"
}